{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "scripts to change into raw files suitable for google seq2seq library\n",
    "\n",
    "following https://google.github.io/seq2seq/nmt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from tensorflow.contrib import learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lines(filenames):\n",
    "    data_files = []\n",
    "    for filename in filenames:\n",
    "        print(\"Reading Tweets_processed_%s.txt\" % filename)\n",
    "        f = pd.read_csv('./Tweets_processed_%s.txt' % filename,\n",
    "                         sep=\"\\t\",\n",
    "                         skiprows=[0],\n",
    "                         error_bad_lines=False,\n",
    "                         names=[\"index\", \"tweet_id\", \"text\", \"user_id\"],\n",
    "                         dtype={\"text\": str, \"user_id\": str, \"tweet_id\": str, \"index\": str})\n",
    "        data_files.append(f)\n",
    "\n",
    "\n",
    "    data_files = pd.concat(data_files)\n",
    "    print(\"Appending all the files\")\n",
    "\n",
    "    count = 0\n",
    "    q_lines = []\n",
    "    a_lines = []\n",
    "    previous = None\n",
    "    for i, row in tqdm(data_files.iterrows()):\n",
    "        try:\n",
    "            index = int(row['index'])\n",
    "        except ValueError:\n",
    "            print(\"ValueError %s\" % row['index'])\n",
    "            index = \"\"\n",
    "        if index:\n",
    "            if previous != None:\n",
    "                if previous[0] == index - 1:\n",
    "                    q_lines.append(str(previous[1]))\n",
    "                    a_lines.append(str(row['text']))\n",
    "                    count += 1\n",
    "            previous = (index, row['text'])\n",
    "\n",
    "    print(\"%s Q&A pairs added\" % count)\n",
    "    return q_lines, a_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q, a = read_lines([\"Train\", \"Valid\", \"Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_idx = list(range(len(q)))\n",
    "random.shuffle(random_idx)\n",
    "train_idx = random_idx[:int(len(random_idx)*0.9)]\n",
    "test_idx = random_idx[int(len(random_idx)*0.9)+1:]\n",
    "print(len(train_idx))\n",
    "print(len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in test_idx[:10]:\n",
    "    print(\"Q: %s A: %s\\n\" % (q[i], a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_q = [q[i] for i in test_idx]\n",
    "len(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_q = [q[i] for i in tqdm(train_idx)]\n",
    "len(train_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_a = [a[i] for i in test_idx]\n",
    "len(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_a = [a[i] for i in tqdm(train_idx)]\n",
    "len(train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file(name, q, a):\n",
    "    with open(\"%s.question\" % name, \"w\") as f1:\n",
    "        with open(\"%s.answer\" % name, \"w\") as f2:\n",
    "            for i in range(len(q)):\n",
    "                f1.write(q[i].replace(\"\\n\", \" \") + \"\\n\")\n",
    "                f2.write(a[i].replace(\"\\n\", \" \") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(name):\n",
    "    with open(\"%s.question\" % name, \"r\") as f1:\n",
    "        with open(\"%s.answer\" % name, \"r\") as f2:\n",
    "            q = [line.rstrip() for line in f1]\n",
    "            a = [line.rstrip() for line in f2]\n",
    "            assert len(q) == len(a)\n",
    "    return q,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if u need to load again\n",
    "test_q, test_a = load_file(\"test_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_q, train_a = load_file(\"train_large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_test_q = [line.split(\" \") for line in tqdm(test_q)]\n",
    "tokens_test_a = [line.split(\" \") for line in tqdm(test_a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_train_q = [line.split(\" \") for line in tqdm(train_q)]\n",
    "tokens_train_a = [line.split(\" \") for line in tqdm(train_a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save only respones with 2~30 tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make into tuples first\n",
    "train = []\n",
    "for i in range(len(tokens_train_q)):\n",
    "    train.append((tokens_train_q[i], tokens_train_a[i]))\n",
    "test = []\n",
    "for i in range(len(tokens_test_q)):\n",
    "    test.append((tokens_test_q[i], tokens_test_a[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_test = list(filter(lambda x: len(x[0]) >= 2 and len(x[0]) <= max_len - 1 and len(x[1]) >= 2 and len(x[1]) <= max_len - 1, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test), len(_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_train = list(filter(lambda x: len(x[0]) >= 2 and len(x[0]) <= max_len - 1 and len(x[1]) >= 2 and len(x[1]) <= max_len - 1, train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train), len(_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for q,a in tqdm(_test):\n",
    "    q.append(\"<EOS>\")\n",
    "    a.append(\"<EOS>\")\n",
    "    for _ in range(max_len - len(a)):\n",
    "        a.append(\"<PAD>\")\n",
    "    for _ in range(max_len - len(q)):\n",
    "        q.append(\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for q,a in tqdm(_train):\n",
    "    q.append(\"<EOS>\")\n",
    "    a.append(\"<EOS>\")\n",
    "    for _ in range(max_len - len(a)):\n",
    "        a.append(\"<PAD>\")\n",
    "    for _ in range(max_len - len(q)):\n",
    "        q.append(\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_train[70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_test = test\n",
    "_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5769660"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_list = []\n",
    "for q,a in tqdm(_test):\n",
    "    total_list.extend(q)\n",
    "    total_list.extend(a)\n",
    "len(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57642542"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for q,a in tqdm(_train):\n",
    "    total_list.extend(q)\n",
    "    total_list.extend(a)\n",
    "len(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'mean',\n",
       " 'the',\n",
       " 'live',\n",
       " 'broadcast',\n",
       " 'in',\n",
       " 'movie',\n",
       " 'theaters',\n",
       " '?',\n",
       " 'nah']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab = Counter(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<PAD>', 29999158),\n",
       " ('<EOS>', 1921418),\n",
       " ('.', 906950),\n",
       " ('i', 770699),\n",
       " ('!', 766157),\n",
       " (',', 572899),\n",
       " ('?', 552936),\n",
       " ('you', 546690),\n",
       " ('the', 478095),\n",
       " ('to', 432458)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create vocab processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = {\"UNK\":0}\n",
    "reverse_vocabulary = {0:\"UNK\"}\n",
    "count = 1\n",
    "for word, _ in vocab.most_common(vocab_size):\n",
    "    vocabulary.update({word: count})\n",
    "    reverse_vocabulary.update({count:word})\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(864548, 864548)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_q = [\" \".join(x[0]) for x in tqdm(_train)]\n",
    "_train_a = [\" \".join(x[1]) for x in tqdm(_train)]\n",
    "len(_train_q), len(_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_test_q = [\" \".join(x[0]) for x in tqdm(_test)]\n",
    "_test_a = [\" \".join(x[1]) for x in tqdm(_test)]\n",
    "len(_test_q), len(_test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_file(\"test_large\", _test_q, _test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file(\"train_large\", _train_q, _train_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test if it loads correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocabulary & idx matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform(qa_pairs):\n",
    "    q_vocab = []\n",
    "    a_vocab = []\n",
    "    \n",
    "    error = 0\n",
    "    for q,a in tqdm(qa_pairs):\n",
    "        if len(q) == len(a):\n",
    "            q_vocab.append([vocabulary[token] if token in vocabulary else 0 for token in q])\n",
    "            a_vocab.append([vocabulary[token] if token in vocabulary else 0 for token in a])\n",
    "        else:\n",
    "            error += 1\n",
    "    print(\"transform complete with error rate %.3f\" % float(error/len(qa_pairs)))\n",
    "    return np.array(q_vocab), np.array(a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transform complete with error rate 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((96161, 30), (96161, 30))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q_vocab, test_a_vocab = transform(_test)\n",
    "test_q_vocab.shape, test_a_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515315/|/ 60%|| 515315/864548 [00:25<00:17, 20400.33it/s]\n",
      "transform complete with error rate 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((864546, 30), (864546, 30))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q_vocab, train_a_vocab = transform(_train)\n",
    "train_q_vocab.shape, train_a_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse(row, reverse_vocab):\n",
    "    return [reverse_vocab[id] for id in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"won't\",\n",
       " 'eat',\n",
       " 'either',\n",
       " '.',\n",
       " 'he',\n",
       " 'is',\n",
       " 'so',\n",
       " 'picky',\n",
       " 'these',\n",
       " 'days',\n",
       " '.',\n",
       " '<EOS>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse(train_q_vocab[100], reverse_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('train_q_large.npy', train_q_vocab)\n",
    "np.save('train_a_large.npy', train_a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('test_q_large.npy', test_q_vocab)\n",
    "np.save('test_a_large.npy', test_a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_ = {\"word2id\": vocabulary, \"id2word\":reverse_vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('large.vocab', 'wb') as f:\n",
    "    pickle.dump(vocab_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "widgets": {
   "state": {
    "20a0f1304e9f4bff87136f975b0f32f5": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "2dc052e9f0e2465bbb698dbd7cbe8af2": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "3f75595b419146f484bdc04bcebe98bc": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    },
    "485ba910f5884ee58fb4d101ea595a95": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "53545efd65f046169de6f9cd3c9dfc2a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "5fc0a306434646ac9158e0b339edd53a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "670e43c7e5af40a0abd893ee4aa81688": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "7ee69af54de347cd9da1301ccde3f28e": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "8d9ac074355f4b4d995f857fbc7706f2": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    },
    "a6f9943b86444a27807b9b9892e8674d": {
     "views": [
      {
       "cell_index": 50
      }
     ]
    },
    "d10f78e78d9a4e1baae96a7dfaed1c2d": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "e9899726a1c8468c8eded3e0abee2ff8": {
     "views": [
      {
       "cell_index": 49
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
